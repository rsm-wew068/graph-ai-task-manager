import os
import psycopg2
from psycopg2.extras import RealDictCursor, Json
import pandas as pd
from typing import List, Dict, Optional, Tuple
import logging
from datetime import datetime
import json

# Handle dotenv import gracefully for deployment environments
try:
    from dotenv import load_dotenv

    load_dotenv()
except ImportError:
    pass

logger = logging.getLogger(__name__)


class PostgreSQLDatabase:
    """
    PostgreSQL database manager for the automated task manager.
    Handles storing parsed emails and validated tasks.
    Optimized for Neon PostgreSQL cloud platform.
    """

    def __init__(
        self,
        host: str = None,
        port: int = None,
        database: str = None,
        username: str = None,
        password: str = None,
        connection_string: str = None,
    ):
        # Support both individual parameters and Neon connection string
        self.connection_string = connection_string or os.getenv("DATABASE_URL")

        if self.connection_string:
            # Use Neon connection string (preferred method)
            self.host = None
            self.port = None
            self.database = None
            self.username = None
            self.password = None
        else:
            # Fallback to individual parameters
            self.host = host or os.getenv("POSTGRES_HOST", "localhost")
            self.port = port or int(os.getenv("POSTGRES_PORT", "5432"))
            self.database = database or os.getenv("POSTGRES_DB", "task_manager")
            self.username = username or os.getenv("POSTGRES_USER", "postgres")
            self.password = password or os.getenv("POSTGRES_PASSWORD", "password")

        self.connection = None

    def connect(self) -> bool:
        """Establish connection to PostgreSQL database (Neon optimized)."""
        try:
            if self.connection_string:
                # Use Neon connection string (includes SSL and pooling)
                self.connection = psycopg2.connect(
                    self.connection_string,
                    cursor_factory=RealDictCursor,
                    sslmode="require",  # Neon requires SSL
                )
                logger.info("‚úÖ Connected to Neon PostgreSQL database")
            else:
                # Fallback to individual parameters
                self.connection = psycopg2.connect(
                    host=self.host,
                    port=self.port,
                    database=self.database,
                    user=self.username,
                    password=self.password,
                    cursor_factory=RealDictCursor,
                    sslmode="prefer",
                )
                logger.info("‚úÖ Connected to PostgreSQL database")

            self.connection.autocommit = True
            return True
        except Exception as e:
            logger.error(f"‚ùå Failed to connect to PostgreSQL: {e}")
            return False

    def close(self):
        """Close PostgreSQL connection."""
        if self.connection:
            self.connection.close()
            self.connection = None

    def create_tables(self) -> bool:
        """Create the necessary tables if they don't exist."""
        if not self.connection:
            if not self.connect():
                return False

        try:
            with self.connection.cursor() as cursor:
                # Create parsed_email table
                cursor.execute(
                    """
                    CREATE TABLE IF NOT EXISTS parsed_email (
                        id SERIAL PRIMARY KEY,
                        message_id VARCHAR(255) UNIQUE NOT NULL,
                        date_received TIMESTAMP WITH TIME ZONE NOT NULL,
                        from_email VARCHAR(255),
                        to_email TEXT,
                        cc_email TEXT,
                        bcc_email TEXT,
                        from_name VARCHAR(255),
                        to_name TEXT,
                        cc_name TEXT,
                        bcc_name TEXT,
                        subject TEXT,
                        content TEXT NOT NULL,
                        content_length INTEGER,
                        processed_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
                        file_source VARCHAR(255)
                    )
                """
                )

                # Create indexes for parsed_email
                indexes = [
                    "CREATE INDEX IF NOT EXISTS idx_parsed_email_message_id ON parsed_email(message_id)",
                    "CREATE INDEX IF NOT EXISTS idx_parsed_email_date_received ON parsed_email(date_received)",
                    "CREATE INDEX IF NOT EXISTS idx_parsed_email_from_email ON parsed_email(from_email)",
                    "CREATE INDEX IF NOT EXISTS idx_parsed_email_subject ON parsed_email(subject)",
                ]

                for index in indexes:
                    cursor.execute(index)

                # Create tasks table
                cursor.execute(
                    """
                    CREATE TABLE IF NOT EXISTS tasks (
                        id SERIAL PRIMARY KEY,
                        email_id INTEGER,
                        message_id VARCHAR(255),
                        task_name TEXT NOT NULL,
                        task_description TEXT,
                        due_date DATE,
                        received_date DATE,
                        status VARCHAR(255) DEFAULT 'not started',
                        topic VARCHAR(255),
                        priority_level VARCHAR(255),
                        sender VARCHAR(255),
                        assigned_to VARCHAR(255),
                        email_source VARCHAR(255),
                        spam BOOLEAN DEFAULT false,
                        validation_status VARCHAR(255) DEFAULT 'llm',
                        confidence_score DOUBLE PRECISION,
                        raw_json JSONB,
                        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
                        FOREIGN KEY (email_id) REFERENCES parsed_email(id) ON DELETE SET NULL
                    )
                """
                )

                # Create indexes for tasks
                task_indexes = [
                    "CREATE INDEX IF NOT EXISTS idx_tasks_email_id ON tasks(email_id)",
                    "CREATE INDEX IF NOT EXISTS idx_tasks_message_id ON tasks(message_id)",
                    "CREATE INDEX IF NOT EXISTS idx_tasks_topic ON tasks(topic)",
                    "CREATE INDEX IF NOT EXISTS idx_tasks_sender ON tasks(sender)",
                    "CREATE INDEX IF NOT EXISTS idx_tasks_assigned_to ON tasks(assigned_to)",
                    "CREATE INDEX IF NOT EXISTS idx_tasks_due_date ON tasks(due_date)",
                    "CREATE INDEX IF NOT EXISTS idx_tasks_received_date ON tasks(received_date)",
                    "CREATE INDEX IF NOT EXISTS idx_tasks_status ON tasks(status)",
                    "CREATE INDEX IF NOT EXISTS idx_tasks_validation_status ON tasks(validation_status)",
                ]

                for index in task_indexes:
                    cursor.execute(index)

                # Note: task_collaborators table removed - using flat structure instead

                logger.info("‚úÖ Database tables created successfully")
                return True

        except Exception as e:
            logger.error(f"‚ùå Error creating tables: {e}")
            return False

    def store_parsed_emails(
        self, emails_df: pd.DataFrame, file_source: str = None
    ) -> List[int]:
        """
        Store parsed email data in the parsed_email table.

        Args:
            emails_df: DataFrame with parsed email data
            file_source: Name of the source .mbox file

        Returns:
            List of inserted email IDs
        """
        if not self.connection:
            if not self.connect():
                return []

        try:
            inserted_ids = []

            with self.connection.cursor() as cursor:
                for _, row in emails_df.iterrows():
                    # Convert date to proper format
                    date_received = pd.to_datetime(row["Date"])
                    # Ensure Message-ID is mapped to message_id in DB
                    message_id = row.get("Message-ID") or row.get("message_id") or None
                    cursor.execute(
                        """
                        INSERT INTO parsed_email (
                            message_id, date_received, from_email, to_email, cc_email, bcc_email,
                            from_name, to_name, cc_name, bcc_name, subject, content, 
                            content_length, file_source
                        ) VALUES (
                            %(message_id)s, %(date_received)s, %(from_email)s, %(to_email)s, 
                            %(cc_email)s, %(bcc_email)s, %(from_name)s, %(to_name)s, 
                            %(cc_name)s, %(bcc_name)s, %(subject)s, %(content)s, 
                            %(content_length)s, %(file_source)s
                        ) ON CONFLICT (message_id) DO UPDATE SET
                            processed_at = CURRENT_TIMESTAMP
                        RETURNING id
                        """,
                        {
                            "message_id": row[
                                "Message-ID"
                            ],  # <-- Always use Message-ID from DataFrame
                            "date_received": row["Date"],
                            "from_email": row["From"],
                            "to_email": row["To"],
                            "cc_email": row.get("Cc"),
                            "bcc_email": row.get("Bcc"),
                            "from_name": row.get("Name-From"),
                            "to_name": row.get("Name-To"),
                            "cc_name": row.get("Name-Cc"),
                            "bcc_name": row.get("Name-Bcc"),
                            "subject": row["Subject"],
                            "content": row["content"],
                            "content_length": (
                                len(row["content"]) if row["content"] else 0
                            ),
                            "file_source": file_source,
                        },
                    )

                    result = cursor.fetchone()
                    if result:
                        inserted_ids.append(result["id"])

            logger.info(f"‚úÖ Stored {len(inserted_ids)} parsed emails")
            return inserted_ids

        except Exception as e:
            logger.error(f"‚ùå Error storing parsed emails: {e}")
            return []

    def store_validated_tasks(self, validated_tasks: List[Dict]) -> List[int]:
        """
        Store validated task data in the tasks table (flat structure).

        Args:
            validated_tasks: List of validated task dictionaries (flat structure)

        Returns:
            List of inserted task IDs
        """
        if not self.connection:
            if not self.connect():
                return []

        try:
            inserted_task_ids = []

            with self.connection.cursor() as cursor:
                for task_data in validated_tasks:
                    # Validate flat structure
                    required_fields = [
                        "task_name",
                        "task_description",
                        "topic",
                        "message_id",
                    ]

                    if not isinstance(task_data, dict):
                        logger.error("Invalid task JSON: Must be a dictionary")
                        continue

                    # Check required fields
                    missing_fields = []
                    for field in required_fields:
                        if field not in task_data or not task_data[field]:
                            missing_fields.append(field)

                    if missing_fields:
                        logger.error(
                            f"Invalid task JSON: Missing required fields: {missing_fields}"
                        )
                        continue

                    # Insert flat task data
                    task_id = self._insert_flat_task(cursor, task_data)
                    if task_id:
                        inserted_task_ids.append(task_id)

            logger.info(
                f"‚úÖ Successfully stored {len(inserted_task_ids)} validated tasks"
            )
            return inserted_task_ids

        except Exception as e:
            logger.error(f"‚ùå Error storing validated tasks: {e}")
            return []

    # Old _insert_single_task method removed - using _insert_flat_task instead

    def _insert_flat_task(self, cursor, task_data: Dict) -> Optional[int]:
        """Insert a single flat task into the tasks table."""
        try:
            # Try to find corresponding email in parsed_email table
            email_id = None
            message_id = task_data.get("message_id")
            if message_id:
                cursor.execute(
                    "SELECT id FROM parsed_email WHERE message_id = %s LIMIT 1",
                    (message_id,),
                )
                result = cursor.fetchone()
                if result:
                    email_id = result["id"]
                else:
                    logger.warning(
                        f"Email with message_id {message_id} not found in parsed_email table"
                    )

            # Extract task details from flat structure
            task_name = safe_val(task_data.get("task_name"))
            task_description = safe_val(task_data.get("task_description"))
            topic = safe_val(task_data.get("topic"))
            due_date = safe_val(task_data.get("due_date"))
            received_date = safe_val(task_data.get("received_date"))
            status = safe_val(task_data.get("status", "not started"))
            priority_level = safe_val(task_data.get("priority_level"))
            sender = safe_val(task_data.get("sender"))
            assigned_to = safe_val(task_data.get("assigned_to"))
            spam = task_data.get("spam", False)
            validation_status = safe_val(task_data.get("validation_status", "llm"))
            confidence_score = task_data.get("confidence_score")

            # Convert date strings to proper dates
            if due_date:
                try:
                    due_date = pd.to_datetime(due_date).date()
                except:
                    due_date = None

            if received_date:
                try:
                    received_date = pd.to_datetime(received_date).date()
                except:
                    received_date = None

            # Insert task into database
            cursor.execute(
                """
                INSERT INTO tasks (
                    email_id, message_id, task_name, task_description, due_date, 
                    received_date, status, topic, priority_level, sender, assigned_to,
                    email_source, spam, validation_status, confidence_score, raw_json
                ) VALUES (
                    %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s
                ) RETURNING id
            """,
                (
                    email_id,
                    message_id,
                    task_name,
                    task_description,
                    due_date,
                    received_date,
                    status,
                    topic,
                    priority_level,
                    sender,
                    assigned_to,
                    "enron_sample",
                    spam,
                    validation_status,
                    confidence_score,
                    json.dumps(task_data),
                ),
            )

            result = cursor.fetchone()
            if result:
                task_id = result["id"]
                logger.info(f"‚úÖ Inserted task: {task_name}")
                return task_id
            else:
                logger.error("‚ùå Failed to insert task - no ID returned")
                return None

        except Exception as e:
            logger.error(f"‚ùå Error inserting flat task: {e}")
            return None

    def get_parsed_emails(self, limit: int = 100000, offset: int = 0) -> List[Dict]:
        """Retrieve parsed emails from database."""
        if not self.connection:
            if not self.connect():
                return []

        try:
            with self.connection.cursor() as cursor:
                cursor.execute(
                    """
                    SELECT * FROM parsed_email 
                    ORDER BY date_received DESC
                    LIMIT %s OFFSET %s
                """,
                    (limit, offset),
                )

                return [dict(row) for row in cursor.fetchall()]

        except Exception as e:
            logger.error(f"‚ùå Error retrieving parsed emails: {e}")
            return []

    def get_tasks_with_collaborators(
        self, limit: int = 100000, offset: int = 0
    ) -> List[Dict]:
        """Retrieve tasks (simplified - no collaborators table)."""
        if not self.connection:
            if not self.connect():
                return []

        try:
            with self.connection.cursor() as cursor:
                cursor.execute(
                    """
                    SELECT * FROM tasks
                    ORDER BY created_at DESC
                    LIMIT %s OFFSET %s
                """,
                    (limit, offset),
                )

                return [dict(row) for row in cursor.fetchall()]

        except Exception as e:
            logger.error(f"‚ùå Error retrieving tasks: {e}")
            return []

    def get_database_stats(self) -> Dict:
        """Get statistics about the database."""
        if not self.connection:
            if not self.connect():
                return {}

        try:
            with self.connection.cursor() as cursor:
                stats = {}

                # Count parsed emails
                cursor.execute("SELECT COUNT(*) as count FROM parsed_email")
                stats["parsed_emails"] = cursor.fetchone()["count"]

                # Count tasks
                cursor.execute("SELECT COUNT(*) as count FROM tasks")
                stats["tasks"] = cursor.fetchone()["count"]

                # Count collaborators (removed - using flat structure)
                stats["collaborators"] = 0

                # Recent activity
                cursor.execute(
                    """
                    SELECT DATE(processed_at) as date, COUNT(*) as count 
                    FROM parsed_email 
                    WHERE processed_at >= CURRENT_DATE - INTERVAL '7 days'
                    GROUP BY DATE(processed_at)
                    ORDER BY date DESC
                """
                )
                stats["recent_emails"] = [dict(row) for row in cursor.fetchall()]

                return stats

        except Exception as e:
            logger.error(f"‚ùå Error getting database stats: {e}")
            return {}

    def update_task_validation_status(self, task_id: int, status: str) -> bool:
        """Update the validation_status for a task."""
        if not self.connection:
            if not self.connect():
                return False
        try:
            with self.connection.cursor() as cursor:
                cursor.execute(
                    "UPDATE tasks SET validation_status = %s, updated_at = CURRENT_TIMESTAMP WHERE id = %s",
                    (status, task_id),
                )
            return True
        except Exception as e:
            logger.error(f"‚ùå Error updating task validation_status: {e}")
            return False

    # Old update_collaborator_validation_status method removed - using flat structure


# Convenience functions for backward compatibility
def store_parsed_emails(
    emails_df: pd.DataFrame, file_source: str = None, connection_string: str = None
) -> List[int]:
    """Store parsed emails in PostgreSQL database (Neon compatible)."""
    db = PostgreSQLDatabase(connection_string=connection_string)
    if not db.create_tables():
        return []
    return db.store_parsed_emails(emails_df, file_source)


def store_validated_tasks(
    validated_tasks: List[Dict], connection_string: str = None
) -> List[int]:
    """Store validated tasks in PostgreSQL database (Neon compatible)."""
    db = PostgreSQLDatabase(connection_string=connection_string)
    if not db.create_tables():
        return []
    return db.store_validated_tasks(validated_tasks)


def safe_val(val):
    if pd.isnull(val) or val is None:
        return "Unknown"
    return str(val)


if __name__ == "__main__":
    # Test the database connection (Neon compatible)
    db = PostgreSQLDatabase()
    if db.connect():
        if db.connection_string:
            print("‚úÖ Neon PostgreSQL connection successful")
        else:
            print("‚úÖ PostgreSQL connection successful")

        if db.create_tables():
            print("‚úÖ Database tables created")
            print("Database stats:", db.get_database_stats())
        db.close()
    else:
        print("‚ùå PostgreSQL connection failed")
        print(
            "üí° For Neon, set DATABASE_URL environment variable with your connection string"
        )
