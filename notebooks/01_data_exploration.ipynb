{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Email Intelligence Research - Data Exploration\n",
    "\n",
    "This notebook explores the Enron email dataset and demonstrates the power of our AI system with real data.\n",
    "\n",
    "## Research Objectives\n",
    "1. Load and explore the complete Enron dataset\n",
    "2. Analyze email patterns and communication networks\n",
    "3. Demonstrate descriptive analytics capabilities\n",
    "4. Store processed data in S3 for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import boto3\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üìä Email Intelligence Research Pipeline - Data Exploration\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"üïê Started at: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS S3 Setup\n",
    "s3_client = boto3.client('s3')\n",
    "s3_resource = boto3.resource('s3')\n",
    "\n",
    "# S3 bucket names (from CDK deployment)\n",
    "RAW_DATA_BUCKET = 'email-intelligence-raw-data'\n",
    "PROCESSED_DATA_BUCKET = 'email-intelligence-processed-data'\n",
    "RESULTS_BUCKET = 'email-intelligence-results'\n",
    "\n",
    "print(\"üîó AWS S3 Configuration:\")\n",
    "print(f\"   Raw Data: {RAW_DATA_BUCKET}\")\n",
    "print(f\"   Processed: {PROCESSED_DATA_BUCKET}\")\n",
    "print(f\"   Results: {RESULTS_BUCKET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Enron Dataset\n",
    "MAILDIR_PATH = '/home/ec2-user/maildir'  # Path to extracted Enron dataset\n",
    "\n",
    "def load_enron_dataset(maildir_path, limit=1000):\n",
    "    \"\"\"\n",
    "    Load Enron email dataset for research analysis\n",
    "    This demonstrates the system's power with real data\n",
    "    \"\"\"\n",
    "    emails = []\n",
    "    maildir = Path(maildir_path)\n",
    "    \n",
    "    if not maildir.exists():\n",
    "        print(f\"‚ùå Maildir not found at {maildir_path}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    print(f\"üìß Loading Enron dataset from {maildir_path}...\")\n",
    "    \n",
    "    # Target high-volume users for research\n",
    "    target_users = [\n",
    "        \"kaminski-v\", \"beck-s\", \"allen-p\", \"lay-k\", \"skilling-j\",\n",
    "        \"dasovich-j\", \"kean-s\", \"mann-k\", \"delainey-d\", \"farmer-d\"\n",
    "    ]\n",
    "    \n",
    "    count = 0\n",
    "    for user_dir in maildir.iterdir():\n",
    "        if not user_dir.is_dir() or user_dir.name not in target_users:\n",
    "            continue\n",
    "            \n",
    "        print(f\"   üìÅ Processing {user_dir.name}...\")\n",
    "        \n",
    "        # Process different email folders\n",
    "        for subfolder in [\"sent_items\", \"inbox\", \"_sent_mail\", \"sent\", \"all_documents\"]:\n",
    "            folder_path = user_dir / subfolder\n",
    "            if folder_path.exists():\n",
    "                for email_file in folder_path.iterdir():\n",
    "                    if email_file.is_file() and count < limit:\n",
    "                        email_data = parse_email_file(email_file)\n",
    "                        if email_data:\n",
    "                            emails.append(email_data)\n",
    "                            count += 1\n",
    "                            \n",
    "                            if count % 100 == 0:\n",
    "                                print(f\"      ‚ö° Loaded {count} emails...\")\n",
    "                    \n",
    "                    if count >= limit:\n",
    "                        break\n",
    "            \n",
    "            if count >= limit:\n",
    "                break\n",
    "        \n",
    "        if count >= limit:\n",
    "            break\n",
    "    \n",
    "    df = pd.DataFrame(emails)\n",
    "    print(f\"‚úÖ Loaded {len(df)} emails for research analysis\")\n",
    "    return df\n",
    "\n",
    "def parse_email_file(file_path):\n",
    "    \"\"\"\n",
    "    Parse individual email file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        email = {\n",
    "            'file_path': str(file_path),\n",
    "            'user': file_path.parts[-3],  # Extract user from path\n",
    "            'folder': file_path.parts[-2],  # Extract folder\n",
    "            'subject': '',\n",
    "            'from': '',\n",
    "            'to': [],\n",
    "            'cc': [],\n",
    "            'date': '',\n",
    "            'body': '',\n",
    "            'body_length': 0\n",
    "        }\n",
    "        \n",
    "        lines = content.split('\\n')\n",
    "        body_start = 0\n",
    "        \n",
    "        # Parse headers\n",
    "        for i, line in enumerate(lines):\n",
    "            line = line.strip()\n",
    "            \n",
    "            if line.startswith('Subject: '):\n",
    "                email['subject'] = line[9:].strip()\n",
    "            elif line.startswith('From: '):\n",
    "                email['from'] = extract_email_address(line[6:])\n",
    "            elif line.startswith('To: '):\n",
    "                email['to'] = parse_recipients(line[4:])\n",
    "            elif line.startswith('Cc: '):\n",
    "                email['cc'] = parse_recipients(line[4:])\n",
    "            elif line.startswith('Date: '):\n",
    "                email['date'] = line[6:].strip()\n",
    "            elif line == '':\n",
    "                body_start = i + 1\n",
    "                break\n",
    "        \n",
    "        # Extract body\n",
    "        if body_start < len(lines):\n",
    "            email['body'] = '\\n'.join(lines[body_start:]).strip()\n",
    "            email['body_length'] = len(email['body'])\n",
    "        \n",
    "        # Only return emails with meaningful content\n",
    "        if email['body_length'] > 50 and email['subject']:\n",
    "            return email\n",
    "            \n",
    "    except Exception as e:\n",
    "        pass  # Skip problematic files\n",
    "    \n",
    "    return None\n",
    "\n",
    "def extract_email_address(email_str):\n",
    "    \"\"\"Extract clean email address\"\"\"\n",
    "    import re\n",
    "    match = re.search(r'([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})', email_str)\n",
    "    if match:\n",
    "        return match.group(1).lower().strip()\n",
    "    return email_str.strip().lower()\n",
    "\n",
    "def parse_recipients(recipients_str):\n",
    "    \"\"\"Parse recipient list\"\"\"\n",
    "    recipients = []\n",
    "    for recipient in recipients_str.split(','):\n",
    "        email_addr = extract_email_address(recipient.strip())\n",
    "        if '@' in email_addr:\n",
    "            recipients.append(email_addr)\n",
    "    return recipients\n",
    "\n",
    "# Load the dataset\n",
    "emails_df = load_enron_dataset(MAILDIR_PATH, limit=2000)  # Load 2000 emails for research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Overview and Statistics\n",
    "print(\"üìä ENRON DATASET RESEARCH ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if not emails_df.empty:\n",
    "    print(f\"üìß Total Emails Loaded: {len(emails_df):,}\")\n",
    "    print(f\"üë• Unique Users: {emails_df['user'].nunique()}\")\n",
    "    print(f\"üìÅ Email Folders: {emails_df['folder'].nunique()}\")\n",
    "    print(f\"üìù Average Body Length: {emails_df['body_length'].mean():.0f} characters\")\n",
    "    print(f\"üìà Total Characters Processed: {emails_df['body_length'].sum():,}\")\n",
    "    \n",
    "    # Display sample data\n",
    "    print(\"\\nüìã Sample Email Data:\")\n",
    "    display(emails_df[['user', 'folder', 'subject', 'from', 'body_length']].head(10))\n",
    "    \n",
    "    # User distribution\n",
    "    print(\"\\nüë• Emails by User:\")\n",
    "    user_counts = emails_df['user'].value_counts()\n",
    "    print(user_counts)\n",
    "    \n",
    "    # Folder distribution\n",
    "    print(\"\\nüìÅ Emails by Folder:\")\n",
    "    folder_counts = emails_df['folder'].value_counts()\n",
    "    print(folder_counts)\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No emails loaded. Check dataset path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Dataset Characteristics\n",
    "if not emails_df.empty:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Email distribution by user\n",
    "    user_counts.head(10).plot(kind='bar', ax=axes[0,0], color='skyblue')\n",
    "    axes[0,0].set_title('üìß Top 10 Users by Email Count')\n",
    "    axes[0,0].set_xlabel('User')\n",
    "    axes[0,0].set_ylabel('Email Count')\n",
    "    axes[0,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Email body length distribution\n",
    "    emails_df['body_length'].hist(bins=50, ax=axes[0,1], color='lightgreen', alpha=0.7)\n",
    "    axes[0,1].set_title('üìù Email Body Length Distribution')\n",
    "    axes[0,1].set_xlabel('Body Length (characters)')\n",
    "    axes[0,1].set_ylabel('Frequency')\n",
    "    \n",
    "    # Folder distribution\n",
    "    folder_counts.plot(kind='pie', ax=axes[1,0], autopct='%1.1f%%')\n",
    "    axes[1,0].set_title('üìÅ Email Distribution by Folder')\n",
    "    axes[1,0].set_ylabel('')\n",
    "    \n",
    "    # Subject length analysis\n",
    "    emails_df['subject_length'] = emails_df['subject'].str.len()\n",
    "    emails_df['subject_length'].hist(bins=30, ax=axes[1,1], color='orange', alpha=0.7)\n",
    "    axes[1,1].set_title('üìã Subject Length Distribution')\n",
    "    axes[1,1].set_xlabel('Subject Length (characters)')\n",
    "    axes[1,1].set_ylabel('Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save visualization to S3\n",
    "    plt.savefig('/tmp/dataset_overview.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    try:\n",
    "        s3_client.upload_file(\n",
    "            '/tmp/dataset_overview.png',\n",
    "            RESULTS_BUCKET,\n",
    "            'visualizations/dataset_overview.png'\n",
    "        )\n",
    "        print(\"‚úÖ Visualization saved to S3\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not save to S3: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Communication Network Analysis\n",
    "if not emails_df.empty:\n",
    "    print(\"üï∏Ô∏è COMMUNICATION NETWORK ANALYSIS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Extract all unique email addresses\n",
    "    all_senders = set(emails_df['from'].dropna())\n",
    "    all_recipients = set()\n",
    "    \n",
    "    for recipients_list in emails_df['to']:\n",
    "        if isinstance(recipients_list, list):\n",
    "            all_recipients.update(recipients_list)\n",
    "    \n",
    "    print(f\"üë• Unique Senders: {len(all_senders)}\")\n",
    "    print(f\"üë• Unique Recipients: {len(all_recipients)}\")\n",
    "    print(f\"üåê Total Network Size: {len(all_senders.union(all_recipients))}\")\n",
    "    \n",
    "    # Top communicators\n",
    "    sender_counts = emails_df['from'].value_counts().head(10)\n",
    "    print(\"\\nüì§ Top Email Senders:\")\n",
    "    for sender, count in sender_counts.items():\n",
    "        print(f\"   {sender}: {count} emails\")\n",
    "    \n",
    "    # Analyze recipient patterns\n",
    "    recipient_counts = {}\n",
    "    for recipients_list in emails_df['to']:\n",
    "        if isinstance(recipients_list, list):\n",
    "            for recipient in recipients_list:\n",
    "                recipient_counts[recipient] = recipient_counts.get(recipient, 0) + 1\n",
    "    \n",
    "    top_recipients = sorted(recipient_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    print(\"\\nüì• Top Email Recipients:\")\n",
    "    for recipient, count in top_recipients:\n",
    "        print(f\"   {recipient}: {count} emails\")\n",
    "    \n",
    "    # Create communication matrix for top users\n",
    "    top_users = list(sender_counts.head(5).index)\n",
    "    communication_matrix = pd.DataFrame(0, index=top_users, columns=top_users)\n",
    "    \n",
    "    for _, email in emails_df.iterrows():\n",
    "        sender = email['from']\n",
    "        if sender in top_users and isinstance(email['to'], list):\n",
    "            for recipient in email['to']:\n",
    "                if recipient in top_users:\n",
    "                    communication_matrix.loc[sender, recipient] += 1\n",
    "    \n",
    "    # Visualize communication matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(communication_matrix, annot=True, cmap='Blues', fmt='d')\n",
    "    plt.title('üï∏Ô∏è Communication Matrix - Top 5 Users')\n",
    "    plt.xlabel('Recipients')\n",
    "    plt.ylabel('Senders')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save communication analysis\n",
    "    plt.savefig('/tmp/communication_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    try:\n",
    "        s3_client.upload_file(\n",
    "            '/tmp/communication_matrix.png',\n",
    "            RESULTS_BUCKET,\n",
    "            'visualizations/communication_matrix.png'\n",
    "        )\n",
    "        print(\"‚úÖ Communication matrix saved to S3\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not save to S3: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Content Analysis - Demonstrate AI Power\n",
    "if not emails_df.empty:\n",
    "    print(\"üß† CONTENT ANALYSIS - AI POWER DEMONSTRATION\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Analyze email subjects for business terms\n",
    "    business_terms = [\n",
    "        'meeting', 'project', 'report', 'budget', 'contract', 'proposal',\n",
    "        'deadline', 'schedule', 'review', 'analysis', 'strategy', 'plan',\n",
    "        'deliverable', 'task', 'urgent', 'important', 'critical', 'asap'\n",
    "    ]\n",
    "    \n",
    "    # Count business terms in subjects\n",
    "    term_counts = {}\n",
    "    for term in business_terms:\n",
    "        count = emails_df['subject'].str.lower().str.contains(term, na=False).sum()\n",
    "        if count > 0:\n",
    "            term_counts[term] = count\n",
    "    \n",
    "    print(\"üìä Business Terms in Email Subjects:\")\n",
    "    for term, count in sorted(term_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "        percentage = (count / len(emails_df)) * 100\n",
    "        print(f\"   {term}: {count} emails ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Visualize business terms\n",
    "    if term_counts:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        terms = list(term_counts.keys())\n",
    "        counts = list(term_counts.values())\n",
    "        \n",
    "        plt.bar(terms, counts, color='lightcoral', alpha=0.8)\n",
    "        plt.title('üìä Business Terms Frequency in Email Subjects')\n",
    "        plt.xlabel('Business Terms')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Save business terms analysis\n",
    "        plt.savefig('/tmp/business_terms.png', dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        try:\n",
    "            s3_client.upload_file(\n",
    "                '/tmp/business_terms.png',\n",
    "                RESULTS_BUCKET,\n",
    "                'visualizations/business_terms.png'\n",
    "            )\n",
    "            print(\"‚úÖ Business terms analysis saved to S3\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not save to S3: {e}\")\n",
    "    \n",
    "    # Sample high-value emails for AI processing\n",
    "    business_emails = emails_df[\n",
    "        emails_df['subject'].str.lower().str.contains('|'.join(business_terms[:5]), na=False)\n",
    "    ].head(10)\n",
    "    \n",
    "    print(f\"\\nüéØ Found {len(business_emails)} high-value business emails for AI processing:\")\n",
    "    for idx, email in business_emails.iterrows():\n",
    "        print(f\"   üìß {email['subject'][:60]}... (from: {email['from']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Processed Dataset to S3\n",
    "if not emails_df.empty:\n",
    "    print(\"üíæ SAVING PROCESSED DATASET TO S3\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    # Create comprehensive dataset summary\n",
    "    dataset_summary = {\n",
    "        'processing_date': datetime.now().isoformat(),\n",
    "        'total_emails': len(emails_df),\n",
    "        'unique_users': emails_df['user'].nunique(),\n",
    "        'unique_senders': len(all_senders),\n",
    "        'unique_recipients': len(all_recipients),\n",
    "        'total_characters': emails_df['body_length'].sum(),\n",
    "        'avg_body_length': emails_df['body_length'].mean(),\n",
    "        'business_terms_found': term_counts,\n",
    "        'top_users': user_counts.head(10).to_dict(),\n",
    "        'folder_distribution': folder_counts.to_dict(),\n",
    "        'dataset_quality': {\n",
    "            'emails_with_subjects': emails_df['subject'].notna().sum(),\n",
    "            'emails_with_senders': emails_df['from'].notna().sum(),\n",
    "            'emails_with_recipients': emails_df['to'].apply(lambda x: len(x) > 0 if isinstance(x, list) else False).sum(),\n",
    "            'avg_subject_length': emails_df['subject_length'].mean()\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save dataset summary\n",
    "    try:\n",
    "        s3_client.put_object(\n",
    "            Bucket=PROCESSED_DATA_BUCKET,\n",
    "            Key='dataset_summary.json',\n",
    "            Body=json.dumps(dataset_summary, indent=2, default=str),\n",
    "            ContentType='application/json'\n",
    "        )\n",
    "        print(\"‚úÖ Dataset summary saved to S3\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not save summary to S3: {e}\")\n",
    "    \n",
    "    # Save processed emails dataset\n",
    "    try:\n",
    "        # Convert to JSON for S3 storage\n",
    "        emails_json = emails_df.to_json(orient='records', indent=2)\n",
    "        \n",
    "        s3_client.put_object(\n",
    "            Bucket=PROCESSED_DATA_BUCKET,\n",
    "            Key='processed_emails.json',\n",
    "            Body=emails_json,\n",
    "            ContentType='application/json'\n",
    "        )\n",
    "        print(\"‚úÖ Processed emails dataset saved to S3\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not save dataset to S3: {e}\")\n",
    "    \n",
    "    # Save high-value business emails for AI processing\n",
    "    try:\n",
    "        business_emails_json = business_emails.to_json(orient='records', indent=2)\n",
    "        \n",
    "        s3_client.put_object(\n",
    "            Bucket=PROCESSED_DATA_BUCKET,\n",
    "            Key='business_emails_for_ai.json',\n",
    "            Body=business_emails_json,\n",
    "            ContentType='application/json'\n",
    "        )\n",
    "        print(\"‚úÖ High-value business emails saved for AI processing\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not save business emails to S3: {e}\")\n",
    "    \n",
    "    print(f\"\\nüìä RESEARCH DATASET READY:\")\n",
    "    print(f\"   üìß {len(emails_df):,} emails processed\")\n",
    "    print(f\"   üß† {len(business_emails)} high-value emails identified for AI\")\n",
    "    print(f\"   üíæ All data stored in S3 for further analysis\")\n",
    "    print(f\"   üöÄ Ready for advanced AI processing in next notebooks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research Summary and Next Steps\n",
    "print(\"üéØ RESEARCH PHASE 1 COMPLETE\")\n",
    "print(\"=\" * 30)\n",
    "print(\"\\n‚úÖ ACCOMPLISHED:\")\n",
    "print(\"   üìä Loaded and analyzed real Enron dataset\")\n",
    "print(\"   üï∏Ô∏è Mapped communication networks\")\n",
    "print(\"   üìà Identified business patterns\")\n",
    "print(\"   üíæ Stored processed data in S3\")\n",
    "print(\"   üé® Generated research visualizations\")\n",
    "\n",
    "print(\"\\nüöÄ NEXT STEPS:\")\n",
    "print(\"   üìù Notebook 02: Advanced AI Processing\")\n",
    "print(\"   üß† Notebook 03: Predictive Modeling\")\n",
    "print(\"   üí° Notebook 04: Prescriptive Analytics\")\n",
    "print(\"   üóÑÔ∏è Notebook 05: Neo4j Graph Analysis\")\n",
    "\n",
    "print(f\"\\nüïê Completed at: {datetime.now()}\")\n",
    "print(\"\\nüéâ This demonstrates the REAL POWER of our AI system with actual data!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}