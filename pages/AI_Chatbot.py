import sys
import os

# Robust path fix for Hugging Face Spaces
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
if parent_dir not in sys.path:
    sys.path.insert(0, parent_dir)

print(f"AI_Chatbot - Parent directory: {parent_dir}")
print(f"Utils directory exists: {os.path.exists(os.path.join(parent_dir, 'utils'))}")

import streamlit as st

try:
    from utils.langgraph_dag import run_agent_chat_round
    print("‚úÖ AI_Chatbot - Successfully imported utils")
except ImportError as e:
    print(f"‚ùå AI_Chatbot - Import error: {e}")
    st.error(f"Import error: {e}")
    st.stop()

st.set_page_config(page_title="ü§ñ Ask the Task Agent", layout="wide")
st.title("ü§ñ Ask the Task Agent")

# Show data status
if (hasattr(st.session_state, 'processing_complete') and
        st.session_state.processing_complete):
    outputs = st.session_state.get("extracted_tasks", [])
    valid_tasks_count = len([
        res for res in outputs
        if "validated_json" in res and res.get("valid", False)
    ])
    st.success(
        f"üìä Ready to answer questions about {valid_tasks_count} tasks "
        f"from your processed emails"
    )
elif (hasattr(st.session_state, 'parsing_complete') and
      st.session_state.parsing_complete):
    st.warning(
        "üìÅ Emails parsed but not yet processed with LLM. "
        "Go to the main page to start LLM processing for Q&A."
    )
else:
    st.info(
        "üìù No data loaded yet. Please upload and process emails "
        "from the main page first to enable Q&A."
    )

# Initialize chat history
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# Display chat history
for message in st.session_state.chat_history:
    st.chat_message("user").write(message["user"])
    st.chat_message("assistant").write(message["assistant"])

# Get new user input
if user_query := st.chat_input("Ask about your tasks, people, or topics..."):
    st.chat_message("user").write(user_query)

    # Run LangGraph reasoning pipeline
    result = run_agent_chat_round(user_query)
    answer = result.get("final_answer", "‚ö†Ô∏è No answer returned.")
    observation = result.get("observation")

    # Show assistant response
    st.chat_message("assistant").write(answer)

    # Show extracted reasoning as expandable with beautiful visualization
    with st.expander("üîç Show Query-Focused Graph Visualization"):
        try:
            # Generate GraphRAG visualization
            from utils.graphrag import GraphRAG
            
            # Create GraphRAG instance and run the query to get result data
            rag = GraphRAG()
            if rag.load_graph_with_embeddings():
                # Re-run the query to get the structured result for visualization
                graphrag_result = rag.query_with_semantic_reasoning(user_query)
                
                # Generate visualization
                viz_filename = f"chat_viz_{len(st.session_state.chat_history)}.html"
                viz_path = rag.visualize_query_results(
                    user_query, 
                    graphrag_result, 
                    f"static/{viz_filename}"
                )
                
                # Display the visualization in Streamlit
                if viz_path and os.path.exists(viz_path):
                    st.markdown("### üîç Query Analysis Visualization")
                    st.markdown(f"**Query:** {user_query}")
                    st.markdown(f"**Confidence:** {graphrag_result.get('confidence_score', 0):.3f}")
                    
                    # Show the interactive graph
                    with open(viz_path, 'r', encoding='utf-8') as f:
                        html_content = f.read()
                    st.components.v1.html(html_content, height=600, scrolling=True)
                    
                    # Show summary stats based on the actual GraphRAG result
                    # Count nodes by type from the graph result
                    tasks_count = 0
                    people_count = 0
                    dates_count = 0
                    
                    try:
                        import pickle
                        with open("/tmp/topic_graph.gpickle", "rb") as f:
                            graph = pickle.load(f)
                        
                        for node in graphrag_result.get('all_nodes', []):
                            if node in graph:
                                attrs = graph.nodes[node]
                                label = attrs.get('label', '')
                                if label == 'Task':
                                    tasks_count += 1
                                elif label == 'Person':
                                    people_count += 1
                                elif label == 'Date':
                                    dates_count += 1
                    except Exception:
                        # Fallback: try to parse from old evidence format
                        evidence = graphrag_result.get('evidence', {})
                        tasks_count = len(evidence.get('tasks', []))
                        people_count = len(evidence.get('people', []))
                        dates_count = len(evidence.get('deadlines', []))
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("üìã Tasks Found", tasks_count)
                    with col2:
                        st.metric("üë• People Found", people_count)
                    with col3:
                        st.metric("üìÖ Deadlines Found", dates_count)
                else:
                    st.error("Could not generate visualization")
            else:
                st.warning("Graph not loaded. Please process emails first.")
                
        except Exception as e:
            st.error(f"Visualization error: {e}")
            # Fallback to text display
            st.markdown("#### üìù Text Context (Fallback)")
            st.text(observation)

    # Save to chat history
    st.session_state.chat_history.append({
        "user": user_query,
        "assistant": answer
    })